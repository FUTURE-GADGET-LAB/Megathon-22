{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p10WIIAAsd2d"
      },
      "source": [
        "# Import Libararies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5c0ilmWr9ht"
      },
      "outputs": [],
      "source": [
        "#Audio Processing Libraries\n",
        "import librosa\n",
        "import librosa.display\n",
        "from scipy import signal\n",
        "\n",
        "#For Playing Audios\n",
        "import IPython.display as ipd\n",
        "\n",
        "#Array Processing\n",
        "import numpy as np\n",
        "\n",
        "#Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Display the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#Deal with .pkl files\n",
        "import pickle\n",
        "\n",
        "#Create a dataframe\n",
        "import pandas as pd\n",
        "\n",
        "#Transform and encode the categorical targets\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Split dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCHVBq5ds3Mi"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ay3SptCs6t6"
      },
      "outputs": [],
      "source": [
        "def features_extractor(file_name):\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=80)\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
        "\n",
        "    return mfccs_scaled_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpmBAAPItDsr"
      },
      "outputs": [],
      "source": [
        "audio_dataset_path = '../input/emergency-vehicle-siren-sounds/sounds/'\n",
        "\n",
        "extracted_features = []\n",
        "for path in os.listdir(audio_dataset_path):\n",
        "    for file in os.listdir(audio_dataset_path+path+\"/\"):\n",
        "        if file.lower().endswith(\".wav\"):\n",
        "            file_name = audio_dataset_path+path+\"/\"+file\n",
        "            data = features_extractor(file_name)  \n",
        "            extracted_features.append([data, path])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFDAZrfFtPY7"
      },
      "outputs": [],
      "source": [
        "f = open('./Extracted_Features.pkl', 'wb')\n",
        "pickle.dump(extracted_features, f)\n",
        "f.close()\n",
        "\n",
        "f = open('./Extracted_Features.pkl', 'rb')\n",
        "Data = pickle.load(f)\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vBHutOOte7W"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(Data,columns=['feature','class'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxWkF2h7tj26"
      },
      "outputs": [],
      "source": [
        "X = np.array(df['feature'].tolist())\n",
        "Y = np.array(df['class'].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGM4ZD_8tqdV"
      },
      "outputs": [],
      "source": [
        "labelencoder = LabelEncoder()\n",
        "y = to_categorical(labelencoder.fit_transform(Y))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYMOlPB9tygZ"
      },
      "outputs": [],
      "source": [
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from keras.callbacks import *\n",
        "from keras import backend as K\n",
        "from sklearn import metrics\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3HQjTZGu_hx"
      },
      "outputs": [],
      "source": [
        "X_train_features  = X_train.reshape(len(X_train),-1,1)\n",
        "X_test_features = X_test.reshape(len(X_test),-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PeQ4pnyvPQN"
      },
      "outputs": [],
      "source": [
        "def cnn(optimizer=\"adam\", activation=\"relu\", dropout_rate=0.5):\n",
        "    K.clear_session()\n",
        "    inputs = Input(shape=(X_train_features.shape[1], X_train_features.shape[2]))\n",
        "    \n",
        "    #First Conv1D layer\n",
        "    conv = Conv1D(3, 13, padding='same', activation=activation)(inputs)\n",
        "    if dropout_rate != 0:\n",
        "        conv = Dropout(dropout_rate)(conv)\n",
        "    conv = MaxPooling1D(2)(conv)\n",
        "\n",
        "    #Second Conv1D layer\n",
        "    conv = Conv1D(16, 11, padding='same', activation=activation)(conv)\n",
        "    if dropout_rate != 0:\n",
        "        conv = Dropout(dropout_rate)(conv)\n",
        "    conv = MaxPooling1D(2)(conv)\n",
        "    \n",
        "    #MaxPooling 1D\n",
        "    conv = GlobalMaxPool1D()(conv)\n",
        "    \n",
        "    #Dense Layer \n",
        "    conv = Dense(16, activation=activation)(conv)\n",
        "    outputs = Dense(y_test.shape[1], activation='softmax')(conv)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['acc'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXGMI3tuvV5x"
      },
      "outputs": [],
      "source": [
        "model_cnn = cnn(optimizer=\"adam\", activation=\"relu\", dropout_rate=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XudddxGdvbJo"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor = 'val_accuracy', mode ='max',\n",
        "                          patience = 10, restore_best_weights = True)\n",
        "\n",
        "history = model_cnn.fit(X_train_features, y_train, epochs = 200, \n",
        "                       callbacks = [early_stop],\n",
        "                       batch_size = 64, validation_data = (X_test_features, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojXcZF2XwNHO"
      },
      "outputs": [],
      "source": [
        "_, acc = model_cnn.evaluate(X_test_features, y_test)\n",
        "print(\"Test Accuracy : \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx7eXhU7wSIL"
      },
      "outputs": [],
      "source": [
        "y_pred = model_cnn.predict(X_test_features)\n",
        "\n",
        "conf_mat = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=labelencoder.classes_, yticklabels=labelencoder.classes_, cbar=False)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPUhnnhwwVqx"
      },
      "outputs": [],
      "source": [
        "model_cnn.save('./CNN_Model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0G-N4_Wwaiz"
      },
      "outputs": [],
      "source": [
        "x_train_features  = X_train.reshape(len(X_train),-1, 80)\n",
        "x_test_features = X_test.reshape(len(X_test), -1, 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsB264-bwaX_"
      },
      "outputs": [],
      "source": [
        "def lstm(x_tr):\n",
        "    K.clear_session()\n",
        "    inputs = Input(shape=(x_tr.shape[1], x_tr.shape[2]))\n",
        "    #lstm\n",
        "    x = LSTM(128)(inputs)\n",
        "    x = Dropout(0.5)(x)\n",
        "    #dense\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dense(y_test.shape[1], activation='softmax')(x)\n",
        "    model = Model(inputs, x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    return model\n",
        "model_lstm = lstm(x_train_features)\n",
        "mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "history = model_lstm.fit(x_train_features, y_train, epochs = 1000,\n",
        "                        callbacks = [mc],\n",
        "                        batch_size = 64, validation_data = (x_test_features, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKRfv0yzwreJ"
      },
      "outputs": [],
      "source": [
        "_,acc = model_lstm.evaluate(x_test_features, y_test)\n",
        "print(\"Accuracy:\", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69qrhs2OwuRW"
      },
      "outputs": [],
      "source": [
        "y_pred = model_lstm.predict(x_test_features)\n",
        "\n",
        "conf_mat = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
        "fig, ax = plt.subplots(figsize=(12,10))\n",
        "sns.heatmap(conf_mat, annot=True, fmt='d', xticklabels=labelencoder.classes_, yticklabels=labelencoder.classes_, cbar=False)\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voMJ2TE9wwVi"
      },
      "outputs": [],
      "source": [
        "model_lstm.save('./LSTM')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
